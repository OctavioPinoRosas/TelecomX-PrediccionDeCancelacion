# Telecom X PredicciÃ³n de CancelaciÃ³n (Churn)
## ğŸ§­ MisiÃ³n
Desarrollar modelos predictivos capaces de prever quÃ© clientes tienen mayor probabilidad de cancelar sus servicios. Este repositorio contiene el pipeline de modelado, evaluaciÃ³n e interpretaciÃ³n de resultados que continÃºa el trabajo de limpieza y EDA realizado en la [Parte 1](https://github.com/OctavioPinoRosas/ChallengeTelecomX.git).

## ğŸ¯ Objetivos
- Preparar los datos para el modelado (tratamiento, codificaciÃ³n, normalizaciÃ³n cuando aplique).
- Realizar anÃ¡lisis de correlaciÃ³n y selecciÃ³n de variables.
- Entrenar mÃºltiples modelos de clasificaciÃ³n (baseline, Ãrbol de DecisiÃ³n y Random Forest).
- Evaluar el rendimiento con mÃ©tricas y matrices de confusiÃ³n.
- Interpretar resultados: importancia de variables y principales factores que influyen en la cancelaciÃ³n.
- Elaborar conclusiones y una estrategia de retenciÃ³n basada en los hallazgos.

## ğŸ“¦ Datos (Entrada)
Fuente: [archivo CSV](https://github.com/OctavioPinoRosas/ChallengeTelecomX/blob/main/DataBase/TelecomXData.csv) tratado en la Parte 1 (limpio, columnas relevantes y estandarizadas).  
Ruta sugerida: `DataBase/TelecomXData.csv`  
Target: columna binaria de cancelaciÃ³n (por ej., Churn = 0/1).  

ğŸ› ï¸ PreparaciÃ³n de los datos
- ExtracciÃ³n: carga del CSV tratado (uso de pandas).
- EliminaciÃ³n de columnas irrelevantes: IDs u otros identificadores sin valor predictivo.
- Transformaciones: manejo de nulos, tipos y estandarizaciÃ³n cuando aplique.
- Encoding: variables categÃ³ricas â†’ numÃ©ricas con `pd.get_dummies(drop_first=True)`.
- Balance de clases: anÃ¡lisis de proporciones; aplicaciÃ³n de oversampling (SMOTE) cuando corresponde.
- SeparaciÃ³n de datos: `train_test_split` (80/20) con `stratify`.

## ğŸ“ˆ CorrelaciÃ³n y AnÃ¡lisis Dirigido
- Matriz y mapa de calor de correlaciÃ³n para variables numÃ©ricas.
- AnÃ¡lisis dirigido de relaciones con churn, ejemplos:
- Tiempo de contrato Ã— CancelaciÃ³n
- Gasto total Ã— CancelaciÃ³n
- Visualizaciones (boxplots / scatter) para patrones y tendencias.

## ğŸ§ª Modelos de  Machine Learnong
1. Baseline (Dummy)
Modelo de referencia para contextualizar mejoras. MÃ©tricas: accuracy, precision, recall, F1 y matriz de confusiÃ³n.
2. Decision Tree Classifier
Configuraciones: versiÃ³n sin balanceo y con balanceo (Oversampling `SMOTE`).
BÃºsqueda de hiperparÃ¡metros y validaciÃ³n cruzada.
Matriz de confusiÃ³n e interpretaciÃ³n de errores.
3. RandomForestClassifier
Configuraciones: versiÃ³n sin balanceo y con balanceo (Oversampling `SMOTE`)
BÃºsqueda de hiperparÃ¡metros y validaciÃ³n cruzada.
Matriz de confusiÃ³n e interpretaciÃ³n de errores.

## ğŸ” Mejores HiperparÃ¡metros (ejemplos obtenidos)
Los mejores parÃ¡metros pueden variar segÃºn la semilla y el preprocesamiento. A continuaciÃ³n, ejemplos registrados durante los experimentos:
**1. Modelo DecisionTreeClassifier**
    - Modelo con datos no balanceados
        ```
        {
        'max_depth': 5
        }
        ```
    - Modelo con datos balanceados
        ```
        {
        'max_depth': 11
        }
        ```
2. RandomForestClassifier
    - Modelo con datos no balanceados
        ```
        {
        'max_depth': 10,
        'max_features': 'sqrt',
        'min_samples_leaf': 4,
        'min_samples_split': 10,
        'n_estimators': 200,
        }
        ```
    - Modelo con datos no balanceados
        ```
        {
        'max_depth': None,
        'max_features': 'sqrt',
        'min_samples_leaf': 2,
        'min_samples_split': 2,
        'n_estimators': 300,
        }
        ```
## ğŸ“Š Resultados (Test)

- **Resumen por escenario (clase positiva = churn (CancelaciÃ³n) = 1):**

|Modelo	      |Balanceo |Accuracy  |Precision |Recall (clase 1) | F1-score (clase 1)|
|-------------|---------|----------|----------|-----------------|-------------|        
|DecisionTree | No      | 0.78	   | 0.59     | 0.52	        | 0.55 |
|DecisionTree |	SÃ­      | 0.73 	   | 0.48	  | 0.65            | 0.55 |
|RandomForest |	No      | 0.80	   | 0.61     | 0.51	        | 0.57 |
|RandomForest |	SÃ­      | 0.78     | 0.56     | 0.63	        | 0.59 |

- **Matriz de confusiÃ³n:**  

    **1. Modelo DecisionTreeClassifier**  
      
    ![alt Matrices de confusiÃ³n DecisionTreeClassifier](Assets/DecisionTreeClassifier.png)

    **2. RandomForestClassifier**  

    ![alt Matrices de confusiÃ³n RandomForestClassifier](Assets/RandomForestClassifier.png)

## ğŸ§  Principales Factores que Influyen en la CancelaciÃ³n
Basado en importancias del modelo y anÃ¡lisis dirigido.

1. Factores que aumentan la probabilidad de churn
    - Contratos mensuales frente a perÃ­odos mÃ¡s largos.
    - Cargos adicionales elevados (servicios extras no percibidos como valor).
    - Baja permanencia (clientes nuevos/recientes).
    - Ausencia de paquetes/beneficios (descuentos, combos, fidelizaciÃ³n).

2. Factores que disminuyen la probabilidad de churn
    - Contratos anuales o de mayor duraciÃ³n.
    - Descuentos o programas de fidelidad.
    - AntigÃ¼edad alta (clientes con mayor tenure).
    - Soporte y atenciÃ³n al cliente consistentes.

## âœ… SelecciÃ³n del Modelo
Modelo elegido: **RandomForestClassifier** con balanceo (Oversampling `SMOTE`).  
Motivo: mejor recall y F1 de la clase 1, que es prioritaria para retenciÃ³n de clientes.  
Trade-off aceptado: ligera reducciÃ³n de accuracy global frente a una mejor detecciÃ³n de verdaderos positivos (clientes que realmente cancelan).  

## ğŸ§© Estrategia de RetenciÃ³n (a partir de los hallazgos)
- Ofertas proactivas a clientes con alto riesgo (descuentos, paquetes).
- FidelizaciÃ³n por contrato: incentivos por migrar de mensual a anual/bianual.
- Alertas tempranas: monitoreo de seÃ±ales (baja permanencia, quejas, tickets frecuentes).
- OptimizaciÃ³n de precios: revisar cargos adicionales y percepciÃ³n de valor.

## ğŸ—‚ï¸ Estructura del Repositorio
```
TelecomX-PredicciÃ³nDeCancelacion/
â”œâ”€ ğŸ“‚Assets/
â”‚ â””â”€ DecisionTreeClassifier.png
â”‚ â””â”€ RandomForestClassifier.png
â”œâ”€ ğŸ“‚DataBase/
â”‚ â””â”€ TelecomXData.csv
â”œâ”€ ğŸ“‚Metadata/
â”‚ â””â”€ TelecomX_diccionario.md
â”œâ”€ ğŸ“‚Notebooks
â”‚ â””â”€ TelecomX_PrediccionDeCancelacion.ipynb
â”œâ”€ ğŸ“„README
â””â”€ ğŸ“„requirements.txt
```

## ğŸ“„ Requisitos
Dependencias (requirements.txt):
```bash
python==3.10.8
pandas==2.3.0
numpy==1.26.4
scikit-learn==1.3.2
imbalanced-learn==0.11.0
matplotlib>=3.9.2
seaborn==0.13.2
plotly==6.2.0
jupyterlab
```

## â–¶ï¸ Instalar y ejecutar
1. Clona este repositorio:  
`https://github.com/OctavioPinoRosas/TelecomX-PrediccionDeCancelacion.git`
2. (Opcional pero recomendado) Crea un entorno virtual:
    ```bash
    python -m venv venv
    source venv/bin/activate   # En Linux/Mac
    venv\Scripts\activate      # En Windows
    ```
3. Instala las dependencias:  
`pip install -r requirements.txt`
4. Ejecuta el notebook y ejecuta cada secciÃ³n en orden

## ğŸ§ª Reproducibilidad
Fijar semillas: random_state=42 (o la que prefieras) en `train_test_split`, `SMOTE` y modelos.

## ğŸ“œ Licencia
Este proyecto se publica bajo licencia MIT.

## ğŸ‘¤ Autor
**Octavio Pino Rosas**  
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/octavio-pino-rosas)  
Email: ğŸ“§ octaviopinoross@gmail.com

**Â¿Sugerencias? Â¡Abre un issue, envÃ­a un pull request o enviame un mensaje/email! ğŸ™Œ**