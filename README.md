# Telecom X Predicci√≥n de Cancelaci√≥n (Churn)
## üß≠ Misi√≥n
Desarrollar modelos predictivos capaces de prever qu√© clientes tienen mayor probabilidad de cancelar sus servicios. Este repositorio contiene el pipeline de modelado, evaluaci√≥n e interpretaci√≥n de resultados que contin√∫a el trabajo de limpieza y EDA realizado en la [Parte 1](https://github.com/OctavioPinoRosas/ChallengeTelecomX.git).

## üéØ Objetivos
- Preparar los datos para el modelado (tratamiento, codificaci√≥n, normalizaci√≥n cuando aplique).
- Realizar an√°lisis de correlaci√≥n y selecci√≥n de variables.
- Entrenar m√∫ltiples modelos de clasificaci√≥n (baseline, √Årbol de Decisi√≥n y Random Forest).
- Evaluar el rendimiento con m√©tricas y matrices de confusi√≥n.
- Interpretar resultados: importancia de variables y principales factores que influyen en la cancelaci√≥n.
- Elaborar conclusiones y una estrategia de retenci√≥n basada en los hallazgos.

## üì¶ Datos (Entrada)
Fuente: [archivo CSV](https://github.com/OctavioPinoRosas/ChallengeTelecomX/blob/main/DataBase/TelecomXData.csv) tratado en la Parte 1 (limpio, columnas relevantes y estandarizadas).  
Ruta sugerida: `DataBase/TelecomXData.csv`  
Target: columna binaria de cancelaci√≥n (por ej., Churn = 0/1).  

üõ†Ô∏è Preparaci√≥n de los datos
- Extracci√≥n: carga del CSV tratado (uso de pandas).
- Eliminaci√≥n de columnas irrelevantes: IDs u otros identificadores sin valor predictivo.
- Transformaciones: manejo de nulos, tipos y estandarizaci√≥n cuando aplique.
- Encoding: variables categ√≥ricas ‚Üí num√©ricas con `pd.get_dummies(drop_first=True)`.
- Balance de clases: an√°lisis de proporciones; aplicaci√≥n de oversampling (SMOTE) cuando corresponde.
- Separaci√≥n de datos: `train_test_split` (80/20) con `stratify`.

## üìà Correlaci√≥n y An√°lisis Dirigido
- Matriz y mapa de calor de correlaci√≥n para variables num√©ricas.
- An√°lisis dirigido de relaciones con churn, ejemplos:
- Tiempo de contrato √ó Cancelaci√≥n
- Gasto total √ó Cancelaci√≥n
- Visualizaciones (boxplots / scatter) para patrones y tendencias.

## üß™ Modelos de  Machine Learnong
1. Baseline (Dummy)
Modelo de referencia para contextualizar mejoras. M√©tricas: accuracy, precision, recall, F1 y matriz de confusi√≥n.
2. Decision Tree Classifier
Configuraciones: versi√≥n sin balanceo y con balanceo (Oversampling `SMOTE`).
B√∫squeda de hiperpar√°metros y validaci√≥n cruzada.
Matriz de confusi√≥n e interpretaci√≥n de errores.
3. RandomForestClassifier
Configuraciones: versi√≥n sin balanceo y con balanceo (Oversampling `SMOTE`)
B√∫squeda de hiperpar√°metros y validaci√≥n cruzada.
Matriz de confusi√≥n e interpretaci√≥n de errores.

## üîç Mejores Hiperpar√°metros (ejemplos obtenidos)
Los mejores par√°metros pueden variar seg√∫n la semilla y el preprocesamiento. A continuaci√≥n, ejemplos registrados durante los experimentos:
1. Modelo DecisionTreeClassifier
    - Modelo con datos no balanceados
        ```
        {
        'max_depth': 5
        }
        ```
        - Modelo con datos balanceados
        ```
        {
        'max_depth': 11
        }
        ```
2. RandomForestClassifier
    - Modelo con datos no balanceados
        ```
        {
        'max_depth': 10,
        'max_features': 'sqrt',
        'min_samples_leaf': 4,
        'min_samples_split': 10,
        'n_estimators': 200,
        }
        ```
    - Modelo con datos no balanceados
        ```
        {
        'max_depth': None,
        'max_features': 'sqrt',
        'min_samples_leaf': 2,
        'min_samples_split': 2,
        'n_estimators': 300,
        }
        ```
## üìä Resultados (Test)

Resumen por escenario (clase positiva = churn = 1):

|Modelo	      |Balanceo |Presicion |Accuracy |Recall (clase 1) | F1 (clase 1)|
|-------------|---------|----------|---------|-----------------|-------------|        
|DecisionTree | No      || 0.78	  |0.52	            |0.55 |
|DecisionTree |	S√≠      || 0.73	  |0.65	            |0.55|
|RandomForest |	No      || 0.80	  |0.51	            |0.57|
|RandomForest |	S√≠      || 0.78	  |0.63	            |0.59|